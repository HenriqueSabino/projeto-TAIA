{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/henriquesabino/miniconda3/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Requirement already satisfied: gym==0.25.2 in /home/henriquesabino/miniconda3/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (0.25.2)\n",
      "Requirement already satisfied: slimevolleygym in /home/henriquesabino/miniconda3/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (0.1.0)\n",
      "Requirement already satisfied: matplotlib in /home/henriquesabino/miniconda3/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (3.7.2)\n",
      "Requirement already satisfied: opencv-python in /home/henriquesabino/miniconda3/lib/python3.11/site-packages (from -r requirements.txt (line 4)) (4.8.0.74)\n",
      "Requirement already satisfied: numpy in /home/henriquesabino/miniconda3/lib/python3.11/site-packages (from -r requirements.txt (line 5)) (1.24.3)\n",
      "Requirement already satisfied: pandas in /home/henriquesabino/miniconda3/lib/python3.11/site-packages (from -r requirements.txt (line 6)) (2.0.3)\n",
      "Requirement already satisfied: pyglet in /home/henriquesabino/miniconda3/lib/python3.11/site-packages (from -r requirements.txt (line 7)) (2.0.9)\n",
      "Requirement already satisfied: shimmy in /home/henriquesabino/miniconda3/lib/python3.11/site-packages (from -r requirements.txt (line 8)) (1.1.0)\n",
      "Requirement already satisfied: stable-baselines3 in /home/henriquesabino/miniconda3/lib/python3.11/site-packages (from -r requirements.txt (line 9)) (2.1.0)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /home/henriquesabino/miniconda3/lib/python3.11/site-packages (from gym==0.25.2->-r requirements.txt (line 1)) (2.2.1)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in /home/henriquesabino/miniconda3/lib/python3.11/site-packages (from gym==0.25.2->-r requirements.txt (line 1)) (0.0.8)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/henriquesabino/miniconda3/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 3)) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/henriquesabino/miniconda3/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 3)) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/henriquesabino/miniconda3/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 3)) (4.41.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/henriquesabino/miniconda3/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 3)) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/henriquesabino/miniconda3/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 3)) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/henriquesabino/miniconda3/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 3)) (10.0.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /home/henriquesabino/miniconda3/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 3)) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/henriquesabino/miniconda3/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 3)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/henriquesabino/miniconda3/lib/python3.11/site-packages (from pandas->-r requirements.txt (line 6)) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/henriquesabino/miniconda3/lib/python3.11/site-packages (from pandas->-r requirements.txt (line 6)) (2023.3)\n",
      "Requirement already satisfied: gymnasium>=0.27.0 in /home/henriquesabino/miniconda3/lib/python3.11/site-packages (from shimmy->-r requirements.txt (line 8)) (0.29.1)\n",
      "Requirement already satisfied: torch>=1.13 in /home/henriquesabino/miniconda3/lib/python3.11/site-packages (from stable-baselines3->-r requirements.txt (line 9)) (2.0.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /home/henriquesabino/miniconda3/lib/python3.11/site-packages (from gymnasium>=0.27.0->shimmy->-r requirements.txt (line 8)) (4.5.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /home/henriquesabino/miniconda3/lib/python3.11/site-packages (from gymnasium>=0.27.0->shimmy->-r requirements.txt (line 8)) (0.0.4)\n",
      "Requirement already satisfied: six>=1.5 in /home/henriquesabino/miniconda3/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib->-r requirements.txt (line 3)) (1.16.0)\n",
      "Requirement already satisfied: filelock in /home/henriquesabino/miniconda3/lib/python3.11/site-packages (from torch>=1.13->stable-baselines3->-r requirements.txt (line 9)) (3.12.2)\n",
      "Requirement already satisfied: sympy in /home/henriquesabino/miniconda3/lib/python3.11/site-packages (from torch>=1.13->stable-baselines3->-r requirements.txt (line 9)) (1.12)\n",
      "Requirement already satisfied: networkx in /home/henriquesabino/miniconda3/lib/python3.11/site-packages (from torch>=1.13->stable-baselines3->-r requirements.txt (line 9)) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/henriquesabino/miniconda3/lib/python3.11/site-packages (from torch>=1.13->stable-baselines3->-r requirements.txt (line 9)) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/henriquesabino/miniconda3/lib/python3.11/site-packages (from torch>=1.13->stable-baselines3->-r requirements.txt (line 9)) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/henriquesabino/miniconda3/lib/python3.11/site-packages (from torch>=1.13->stable-baselines3->-r requirements.txt (line 9)) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/henriquesabino/miniconda3/lib/python3.11/site-packages (from torch>=1.13->stable-baselines3->-r requirements.txt (line 9)) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/henriquesabino/miniconda3/lib/python3.11/site-packages (from torch>=1.13->stable-baselines3->-r requirements.txt (line 9)) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/henriquesabino/miniconda3/lib/python3.11/site-packages (from torch>=1.13->stable-baselines3->-r requirements.txt (line 9)) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/henriquesabino/miniconda3/lib/python3.11/site-packages (from torch>=1.13->stable-baselines3->-r requirements.txt (line 9)) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/henriquesabino/miniconda3/lib/python3.11/site-packages (from torch>=1.13->stable-baselines3->-r requirements.txt (line 9)) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/henriquesabino/miniconda3/lib/python3.11/site-packages (from torch>=1.13->stable-baselines3->-r requirements.txt (line 9)) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/henriquesabino/miniconda3/lib/python3.11/site-packages (from torch>=1.13->stable-baselines3->-r requirements.txt (line 9)) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/henriquesabino/miniconda3/lib/python3.11/site-packages (from torch>=1.13->stable-baselines3->-r requirements.txt (line 9)) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/henriquesabino/miniconda3/lib/python3.11/site-packages (from torch>=1.13->stable-baselines3->-r requirements.txt (line 9)) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/henriquesabino/miniconda3/lib/python3.11/site-packages (from torch>=1.13->stable-baselines3->-r requirements.txt (line 9)) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /home/henriquesabino/.local/lib/python3.11/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.13->stable-baselines3->-r requirements.txt (line 9)) (68.1.2)\n",
      "Requirement already satisfied: wheel in /home/henriquesabino/miniconda3/lib/python3.11/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.13->stable-baselines3->-r requirements.txt (line 9)) (0.38.4)\n",
      "Requirement already satisfied: cmake in /home/henriquesabino/miniconda3/lib/python3.11/site-packages (from triton==2.0.0->torch>=1.13->stable-baselines3->-r requirements.txt (line 9)) (3.27.1)\n",
      "Requirement already satisfied: lit in /home/henriquesabino/miniconda3/lib/python3.11/site-packages (from triton==2.0.0->torch>=1.13->stable-baselines3->-r requirements.txt (line 9)) (16.0.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/henriquesabino/miniconda3/lib/python3.11/site-packages (from jinja2->torch>=1.13->stable-baselines3->-r requirements.txt (line 9)) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/henriquesabino/miniconda3/lib/python3.11/site-packages (from sympy->torch>=1.13->stable-baselines3->-r requirements.txt (line 9)) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym    \n",
    "import slimevolleygym\n",
    "from slimevolleygym import SurvivalRewardEnv\n",
    "import numpy as np\n",
    "from gym.wrappers.gray_scale_observation import GrayScaleObservation\n",
    "from gym.wrappers.resize_observation import ResizeObservation\n",
    "from atari_wrappers import RenderWrapper, BufferWrapper, ImageToPyTorch\n",
    "\n",
    "INPUT_SHAPE = (84, 84)\n",
    "WINDOW_LENGTH = 4\n",
    "\n",
    "env_name = 'SlimeVolleyNoFrameskip-v0'\n",
    "env = gym.make(env_name)\n",
    "env = SurvivalRewardEnv(env)\n",
    "env = RenderWrapper(env)\n",
    "env = ResizeObservation(env, INPUT_SHAPE)\n",
    "env = GrayScaleObservation(env, True)\n",
    "env = ImageToPyTorch(env)\n",
    "env = BufferWrapper(env, WINDOW_LENGTH, np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 42\u001b[0m\n\u001b[1;32m     39\u001b[0m metrics_callback \u001b[39m=\u001b[39m EveryNTimesteps(n_steps\u001b[39m=\u001b[39m\u001b[39m10000\u001b[39m, callback\u001b[39m=\u001b[39mmodel_metrics_callback)\n\u001b[1;32m     41\u001b[0m callbacks\u001b[39m=\u001b[39m[checkpoint_callback, metrics_callback]\n\u001b[0;32m---> 42\u001b[0m model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mlearn(total_timesteps\u001b[39m=\u001b[39;49m(\u001b[39m1e6\u001b[39;49m \u001b[39m-\u001b[39;49m steps_done), log_interval\u001b[39m=\u001b[39;49m\u001b[39m4\u001b[39;49m, callback\u001b[39m=\u001b[39;49mcallbacks)\n\u001b[1;32m     44\u001b[0m record_env \u001b[39m=\u001b[39m RecordVideo(env, \u001b[39m'\u001b[39m\u001b[39m./videos\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     45\u001b[0m obs \u001b[39m=\u001b[39m record_env\u001b[39m.\u001b[39mreset()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/stable_baselines3/dqn/dqn.py:267\u001b[0m, in \u001b[0;36mDQN.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlearn\u001b[39m(\n\u001b[1;32m    259\u001b[0m     \u001b[39mself\u001b[39m: SelfDQN,\n\u001b[1;32m    260\u001b[0m     total_timesteps: \u001b[39mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    265\u001b[0m     progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    266\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m SelfDQN:\n\u001b[0;32m--> 267\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mlearn(\n\u001b[1;32m    268\u001b[0m         total_timesteps\u001b[39m=\u001b[39;49mtotal_timesteps,\n\u001b[1;32m    269\u001b[0m         callback\u001b[39m=\u001b[39;49mcallback,\n\u001b[1;32m    270\u001b[0m         log_interval\u001b[39m=\u001b[39;49mlog_interval,\n\u001b[1;32m    271\u001b[0m         tb_log_name\u001b[39m=\u001b[39;49mtb_log_name,\n\u001b[1;32m    272\u001b[0m         reset_num_timesteps\u001b[39m=\u001b[39;49mreset_num_timesteps,\n\u001b[1;32m    273\u001b[0m         progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[1;32m    274\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/stable_baselines3/common/off_policy_algorithm.py:312\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    309\u001b[0m callback\u001b[39m.\u001b[39mon_training_start(\u001b[39mlocals\u001b[39m(), \u001b[39mglobals\u001b[39m())\n\u001b[1;32m    311\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_timesteps \u001b[39m<\u001b[39m total_timesteps:\n\u001b[0;32m--> 312\u001b[0m     rollout \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollect_rollouts(\n\u001b[1;32m    313\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv,\n\u001b[1;32m    314\u001b[0m         train_freq\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_freq,\n\u001b[1;32m    315\u001b[0m         action_noise\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maction_noise,\n\u001b[1;32m    316\u001b[0m         callback\u001b[39m=\u001b[39;49mcallback,\n\u001b[1;32m    317\u001b[0m         learning_starts\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlearning_starts,\n\u001b[1;32m    318\u001b[0m         replay_buffer\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreplay_buffer,\n\u001b[1;32m    319\u001b[0m         log_interval\u001b[39m=\u001b[39;49mlog_interval,\n\u001b[1;32m    320\u001b[0m     )\n\u001b[1;32m    322\u001b[0m     \u001b[39mif\u001b[39;00m rollout\u001b[39m.\u001b[39mcontinue_training \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[1;32m    323\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/stable_baselines3/common/off_policy_algorithm.py:544\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.collect_rollouts\u001b[0;34m(self, env, callback, train_freq, replay_buffer, action_noise, learning_starts, log_interval)\u001b[0m\n\u001b[1;32m    541\u001b[0m actions, buffer_actions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sample_action(learning_starts, action_noise, env\u001b[39m.\u001b[39mnum_envs)\n\u001b[1;32m    543\u001b[0m \u001b[39m# Rescale and perform action\u001b[39;00m\n\u001b[0;32m--> 544\u001b[0m new_obs, rewards, dones, infos \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39;49mstep(actions)\n\u001b[1;32m    546\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_timesteps \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mnum_envs\n\u001b[1;32m    547\u001b[0m num_collected_steps \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:197\u001b[0m, in \u001b[0;36mVecEnv.step\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[39mStep the environments with the given action\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \n\u001b[1;32m    193\u001b[0m \u001b[39m:param actions: the action\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \u001b[39m:return: observation, reward, done, information\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstep_async(actions)\n\u001b[0;32m--> 197\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstep_wait()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py:58\u001b[0m, in \u001b[0;36mDummyVecEnv.step_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep_wait\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m VecEnvStepReturn:\n\u001b[1;32m     56\u001b[0m     \u001b[39m# Avoid circular imports\u001b[39;00m\n\u001b[1;32m     57\u001b[0m     \u001b[39mfor\u001b[39;00m env_idx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_envs):\n\u001b[0;32m---> 58\u001b[0m         obs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_rews[env_idx], terminated, truncated, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_infos[env_idx] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menvs[env_idx]\u001b[39m.\u001b[39;49mstep(\n\u001b[1;32m     59\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mactions[env_idx]\n\u001b[1;32m     60\u001b[0m         )\n\u001b[1;32m     61\u001b[0m         \u001b[39m# convert to SB3 VecEnv api\u001b[39;00m\n\u001b[1;32m     62\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_dones[env_idx] \u001b[39m=\u001b[39m terminated \u001b[39mor\u001b[39;00m truncated\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/stable_baselines3/common/monitor.py:94\u001b[0m, in \u001b[0;36mMonitor.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mneeds_reset:\n\u001b[1;32m     93\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTried to step environment that needs reset\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 94\u001b[0m observation, reward, terminated, truncated, info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n\u001b[1;32m     95\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrewards\u001b[39m.\u001b[39mappend(\u001b[39mfloat\u001b[39m(reward))\n\u001b[1;32m     96\u001b[0m \u001b[39mif\u001b[39;00m terminated \u001b[39mor\u001b[39;00m truncated:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/shimmy/openai_gym_compatibility.py:257\u001b[0m, in \u001b[0;36mGymV21CompatibilityV0.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep\u001b[39m(\u001b[39mself\u001b[39m, action: ActType) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mtuple\u001b[39m[Any, \u001b[39mfloat\u001b[39m, \u001b[39mbool\u001b[39m, \u001b[39mbool\u001b[39m, \u001b[39mdict\u001b[39m]:\n\u001b[1;32m    249\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Steps through the environment.\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \n\u001b[1;32m    251\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[39m        (observation, reward, terminated, truncated, info)\u001b[39;00m\n\u001b[1;32m    256\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 257\u001b[0m     obs, reward, done, info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgym_env\u001b[39m.\u001b[39;49mstep(action)\n\u001b[1;32m    259\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrender_mode \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    260\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrender()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/gym/core.py:483\u001b[0m, in \u001b[0;36mObservationWrapper.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep\u001b[39m(\u001b[39mself\u001b[39m, action):\n\u001b[1;32m    482\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Returns a modified observation using :meth:`self.observation` after calling :meth:`env.step`.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 483\u001b[0m     step_returns \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n\u001b[1;32m    484\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(step_returns) \u001b[39m==\u001b[39m \u001b[39m5\u001b[39m:\n\u001b[1;32m    485\u001b[0m         observation, reward, terminated, truncated, info \u001b[39m=\u001b[39m step_returns\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/gym/core.py:483\u001b[0m, in \u001b[0;36mObservationWrapper.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep\u001b[39m(\u001b[39mself\u001b[39m, action):\n\u001b[1;32m    482\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Returns a modified observation using :meth:`self.observation` after calling :meth:`env.step`.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 483\u001b[0m     step_returns \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n\u001b[1;32m    484\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(step_returns) \u001b[39m==\u001b[39m \u001b[39m5\u001b[39m:\n\u001b[1;32m    485\u001b[0m         observation, reward, terminated, truncated, info \u001b[39m=\u001b[39m step_returns\n",
      "    \u001b[0;31m[... skipping similar frames: ObservationWrapper.step at line 483 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/gym/core.py:483\u001b[0m, in \u001b[0;36mObservationWrapper.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep\u001b[39m(\u001b[39mself\u001b[39m, action):\n\u001b[1;32m    482\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Returns a modified observation using :meth:`self.observation` after calling :meth:`env.step`.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 483\u001b[0m     step_returns \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n\u001b[1;32m    484\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(step_returns) \u001b[39m==\u001b[39m \u001b[39m5\u001b[39m:\n\u001b[1;32m    485\u001b[0m         observation, reward, terminated, truncated, info \u001b[39m=\u001b[39m step_returns\n",
      "File \u001b[0;32m~/projeto-TAIA/atari_wrappers.py:20\u001b[0m, in \u001b[0;36mRenderWrapper.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep\u001b[39m(\u001b[39mself\u001b[39m, action):\n\u001b[0;32m---> 20\u001b[0m     step_tuple \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mstep(action)\n\u001b[1;32m     21\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlast_obs \u001b[39m=\u001b[39m step_tuple[\u001b[39m0\u001b[39m]\n\u001b[1;32m     22\u001b[0m     \u001b[39mreturn\u001b[39;00m step_tuple\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/gym/core.py:411\u001b[0m, in \u001b[0;36mWrapper.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Steps through the environment with action.\"\"\"\u001b[39;00m\n\u001b[1;32m    407\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgym\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstep_api_compatibility\u001b[39;00m \u001b[39mimport\u001b[39;00m (  \u001b[39m# avoid circular import\u001b[39;00m\n\u001b[1;32m    408\u001b[0m     step_api_compatibility,\n\u001b[1;32m    409\u001b[0m )\n\u001b[0;32m--> 411\u001b[0m \u001b[39mreturn\u001b[39;00m step_api_compatibility(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnew_step_api)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/gym/core.py:522\u001b[0m, in \u001b[0;36mRewardWrapper.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    520\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep\u001b[39m(\u001b[39mself\u001b[39m, action):\n\u001b[1;32m    521\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Modifies the reward using :meth:`self.reward` after the environment :meth:`env.step`.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 522\u001b[0m     step_returns \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n\u001b[1;32m    523\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(step_returns) \u001b[39m==\u001b[39m \u001b[39m5\u001b[39m:\n\u001b[1;32m    524\u001b[0m         observation, reward, terminated, truncated, info \u001b[39m=\u001b[39m step_returns\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/gym/wrappers/order_enforcing.py:37\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_reset:\n\u001b[1;32m     36\u001b[0m     \u001b[39mraise\u001b[39;00m ResetNeeded(\u001b[39m\"\u001b[39m\u001b[39mCannot call env.step() before calling env.reset()\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/gym/wrappers/step_api_compatibility.py:52\u001b[0m, in \u001b[0;36mStepAPICompatibility.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep\u001b[39m(\u001b[39mself\u001b[39m, action):\n\u001b[1;32m     44\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Steps through the environment, returning 5 or 4 items depending on `new_step_api`.\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \n\u001b[1;32m     46\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39m        (observation, reward, terminated, truncated, info) or (observation, reward, done, info)\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m     step_returns \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n\u001b[1;32m     53\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnew_step_api:\n\u001b[1;32m     54\u001b[0m         \u001b[39mreturn\u001b[39;00m step_to_new_api(step_returns)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/gym/wrappers/env_checker.py:39\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[39mreturn\u001b[39;00m env_step_passive_checker(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv, action)\n\u001b[1;32m     38\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 39\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/slimevolleygym/slimevolley.py:803\u001b[0m, in \u001b[0;36mSlimeVolleyEnv.step\u001b[0;34m(self, action, otherAction)\u001b[0m\n\u001b[1;32m    801\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmultiagent:\n\u001b[1;32m    802\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfrom_pixels:\n\u001b[0;32m--> 803\u001b[0m     otherObs \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mflip(obs, \u001b[39m1\u001b[39;49m) \u001b[39m# horizontal flip\u001b[39;00m\n\u001b[1;32m    804\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    805\u001b[0m     otherObs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgame\u001b[39m.\u001b[39magent_left\u001b[39m.\u001b[39mgetObservation()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback, EveryNTimesteps\n",
    "from train_metrics import ModelMetricsCallback\n",
    "from gym.wrappers.record_video import RecordVideo\n",
    "\n",
    "def createOrLoadModel(model_prefix, model_suffix):\n",
    "    if not os.path.exists('./models/'):\n",
    "        return defaultDQNModel(), 0\n",
    "    \n",
    "    files = os.listdir('./models/')\n",
    "\n",
    "    if len(files) == 0:\n",
    "        return defaultDQNModel(), 0\n",
    "\n",
    "    try:\n",
    "        steps = [int(x.removeprefix(model_prefix).removesuffix(model_suffix)) for x in files]\n",
    "        steps.sort()\n",
    "\n",
    "        model_name = f'{model_prefix}{steps[-1]}{model_suffix}'\n",
    "        print(f'Loading {model_name}')\n",
    "        return DQN.load(model_name), steps[-1]\n",
    "    except:\n",
    "        return defaultDQNModel(), 0\n",
    "\n",
    "def defaultDQNModel():\n",
    "    return DQN(\"CnnPolicy\", env, verbose=0, buffer_size=50000)\n",
    "    \n",
    "model, steps_done = createOrLoadModel('dqn_', '_steps.zip')\n",
    "\n",
    "eval_env = gym.make(env_name)\n",
    "eval_env = ResizeObservation(eval_env, INPUT_SHAPE)\n",
    "eval_env = GrayScaleObservation(eval_env, True)\n",
    "eval_env = ImageToPyTorch(eval_env)\n",
    "eval_env = BufferWrapper(eval_env, WINDOW_LENGTH, np.uint8)\n",
    "\n",
    "checkpoint_callback = CheckpointCallback(save_freq=10000, save_path='./models', name_prefix='dqn')\n",
    "model_metrics_callback = ModelMetricsCallback(eval_env, './models',num_episodes=30, verbose=0)\n",
    "metrics_callback = EveryNTimesteps(n_steps=1000, callback=model_metrics_callback)\n",
    "\n",
    "callbacks=[checkpoint_callback, metrics_callback]\n",
    "model = model.learn(total_timesteps=(1e6 - steps_done), log_interval=4, callback=callbacks)\n",
    "\n",
    "record_env = RecordVideo(env, './videos')\n",
    "obs = record_env.reset()\n",
    "\n",
    "done = False\n",
    "while not done:\n",
    "    action, _ = model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, info = record_env.step(int(action))\n",
    "record_env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
